---
title: 'Sea Cucumber: spatial hurdle model'
author: "Laura Graham"
output: 
  html_document: 
    keep_md: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      figures = 'figures/')

library(raster)
library(lubridate)
library(sf)
library(ggsn)
library(gstat)
library(GGally)
library(INLA)
library(knitr)
library(broom)
library(patchwork)
library(tidyverse)

# set up plotting options
theme_set(theme_bw(base_size = 7) + theme(panel.grid = element_blank()))

# Albers equal area coordinate reference system for Mexico:
crs_ea_mex <- "+proj=aea +lat_1=14.5 +lat_2=32.5 +lat_0=24 +lon_0=-105 +x_0=0 +y_0=0 +ellps=GRS80 +datum=NAD83 +units=m +no_defs"
```

## Aim

In this analysis we want to create spatial estimates of sea cucumber abundance within the < 30m depth region of the Gulf of California. 

## Data

```{r load_data}
# sea cucumber abundance and some environmental variables
dat <- read_csv("data/sea_cucumber_data.csv", na = c("", "NA", "ND")) %>% 
  select(site_name, latitude, longitude, date, sc_density) %>% 
  mutate(longitude = -longitude,
         date = dmy(date),
         month = str_sub(date, 1, 7),
         z = case_when(sc_density == 0 ~ 0, 
                       TRUE ~ 1),
         y = case_when(sc_density == 0 ~ NaN,
                       TRUE ~ sc_density)) %>% 
  st_as_sf(coords = c("longitude", "latitude"), 
           crs = 4326) %>% 
  st_transform(crs_ea_mex)
```

We have `r nrow(dat)` observations of sea cucumber densities. These are from `r length(unique(dat$site_name))` sites, collected between `r min(dat$date)` and `r max(dat$date)`.

### Data exploration

What do the sea cucumber densities look like. 

```{r explore_distributions}
ggplot(data = dat, aes(x = sc_density)) + 
  geom_histogram(binwidth = 0.01)
```

Non-zero density ranges from `r min(dat$y, na.rm = TRUE)/100` to `r max(dat$y, na.rm = TRUE)/100`; we will model the abundances (*100) as a negative binomial hurdle model. Occurrence will be fitted with a binomial model. 

### Spatial data

We only want to model and predict within the < 30m depth zone, so let's load this data, plot and create some prediction points. 

```{r spatial_data, fig.width = 6.3, fig.height = 9.5}
# set the boundary for analysis
# currently fixing these boundaries so that we don't get the wide bit - revisit
bounds <- c(xmin = -114.5, ymin = 28, xmax = -112.5, ymax = 30)

# load in the depth data and crop to analysis region
depth_sf <- st_read("data/30m_isobath_baja_california.kml") %>% 
  st_crop(bounds) %>% 
  st_cast("POLYGON") %>% 
  st_zm() %>% 
  st_transform(crs_ea_mex) %>% 
  st_buffer(0) %>% 
  filter(Name != 0) %>% 
  st_cast("MULTIPOLYGON")

# load in the land shapefile and crop to analysis region
map_sf <- st_read("data/bc_shp/bc_municipio.shp") %>% 
  st_crop(bounds) %>% 
  st_transform(crs_ea_mex)

# remove the intersection of land and depth
depth_sf <- st_difference(depth_sf, st_combine(map_sf)) %>% st_cast("MULTIPOLYGON")

depth_sp <- as(depth_sf, "Spatial")

# create a prediction surface
ras <- raster(extent(depth_sp), crs = crs_ea_mex)

res(ras) <- 100
depth_ras <- fasterize::fasterize(depth_sf %>% st_cast("POLYGON"), ras)

pred_dat <- as.data.frame(depth_ras, xy = TRUE) %>% 
  na.omit %>% select(x, y)

f <- list.files("data/quota_shp/", pattern = ".shp", full.names = TRUE)

quotas <- st_read("data/quota_estates.shp")

ggplot() + geom_sf(data = quotas, aes(fill = Estate))

quotas_sp <- as(quotas, "Spatial")

study_site <- ggplot() + 
  geom_sf(data=map_sf, fill = "grey", colour = "grey") +
  geom_sf(data = quotas) +
  geom_sf(data = dat %>% arrange(sc_density), 
             aes(colour = sc_density)) +
  scale_colour_viridis_c(name = "Sea Cucumber\nDensity") + 
  theme(axis.title = element_blank(),
        panel.grid.major=element_line(colour="transparent")) 

ggsave(plot = study_site, filename = "figures/study_site.jpg", dpi = 300, width = 140, units = "mm")
```

```{r spatiotemporal_data, cache = TRUE, fig.width = 15, fig.height = 15}
ggplot() +
  geom_sf(data = dat %>% select(-month), colour = "lightgrey") + 
  geom_sf(data = dat %>% arrange(sc_density), aes(colour = sc_density)) + 
  scale_colour_viridis_c(name = "Sea Cucumber Abundance") + 
  facet_wrap(~month)
```

Date structure in the sampling, will need to account for. 

## INLA Modelling

We will compare 4 different modelling approaches. All approaches are hurdle models where occurrence is modelled using the binomial distribution and density is modelled using the gamma distribution: 

1. null: Intercept-only model
2. temporal: Model with time as random factor
3. spatial: Spatial structure included as a random field (SPDE Matern correlation)
4. spatio-temporal: model with time as random factor and spatial structure as random field

We will also fit each of these with site as a random factor in addition. 

### INLA Mesh

We need a spatial mesh to create the spatial random field. This will be restricted to the convex hull around the prediction points. 

```{r create_mesh}
# Create mesh
pred_dat <- pred_dat %>% as.matrix
coords_dat <- st_coordinates(dat)

ch <- inla.nonconvex.hull(rbind(pred_dat, coords_dat) %>% as.matrix, convex = -0.05)

# NB this mesh could be smaller - when we've got a good analysis going, need to change it. 
mesh <- inla.mesh.2d(boundary = ch,
                     #offset = 0.1,
                     max.edge = 5000)

# get locs of points and plot the mesh with the pred and obs points
plot(mesh)
#points(pred_dat[,1:2], col = 1, pch = 16, cex = 1)
points(coords_dat, col = 2, pch = 16, cex = 1)
mesh$n

# Associate observation locations with mesh vertices
A <- inla.spde.make.A(mesh, loc = coords_dat)
spde <- inla.spde2.matern(mesh, alpha = 2)

A_pred <- inla.spde.make.A(mesh, loc = pred_dat)
```

### INLA Stacks

To model in INLA we need to create data stacks of fitting and prediction data. 

```{r stack_data}
# create the stacks
nobs = nrow(dat)
dat <- mutate(dat, site_name = as.numeric(as.factor(site_name)),
              date = as.numeric(date))
stack_y <- inla.stack(tag = "est.y", 
                      data = list(alldata = cbind(dat$y, NA), link = 1), 
                      A = list(A, A, 1, 1, 1),
                      effects = list(
                        y_field = 1:spde$n.spde,
                        yc_field = 1:spde$n.spde,
                        y_intercept = rep(1, nobs),
                        site = dat$site_name,
                        date = dat$date))

stack_z <- inla.stack(tag = "est.z", 
                      data = list(alldata = cbind(NA, dat$z), link = 2), 
                      A = list(A, 1, 1, 1),
                      effects = list(
                        z_field = 1:spde$n.spde,
                        z_intercept = rep(1, nobs),
                        site = dat$site_name,
                        date = dat$date))

stack_yz <- inla.stack(stack_y, stack_z)
```

### INLA Fitting

Finally, we're going to run the model. We will use a hurdle model approach (binomial for occupancy, negbin for abundance). To do this, we are following Chapter Six of the [INLA SPDE Tutorial](https://folk.ntnu.no/fuglstad/Lund2016/Session6/spde-tutorial.pdf). 

```{r inla_models, eval = FALSE}
# 1. Null (intercept only)
f_null <- alldata ~ -1 + z_intercept + y_intercept
m_null <- inla(f_null, family = c("gamma", "binomial"),
               data = inla.stack.data(stack_yz),
               control.predictor = list(A = inla.stack.A(stack_yz)),
               control.compute = list(dic = TRUE))

f_nulls <- alldata ~ -1 + z_intercept + y_intercept + 
  f(site, model = "iid")
m_nulls <- inla(f_nulls, family = c("gamma", "binomial"),
                data = inla.stack.data(stack_yz),
                control.predictor = list(A = inla.stack.A(stack_yz)),
                control.compute = list(dic = TRUE))

# 2. Time only (random date field)
f_time <- alldata ~ -1 + z_intercept + y_intercept + 
  f(date, model = "rw2")
m_time <- inla(f_time, family = c("gamma", "binomial"),
               data = inla.stack.data(stack_yz),
               control.predictor = list(A = inla.stack.A(stack_yz)),
               control.compute = list(dic = TRUE))

f_times <- alldata ~ -1 + z_intercept + y_intercept + 
  f(date, model = "rw2") + 
  f(site, model = "iid")
m_times <- inla(f_times, family = c("gamma", "binomial"),
                data = inla.stack.data(stack_yz),
                control.predictor = list(A = inla.stack.A(stack_yz)),
                control.compute = list(dic = TRUE, config = TRUE))

# 3. Space only (random spatial field)
f_spatial <- alldata ~ -1 + z_intercept + y_intercept + 
  f(z_field, model = spde) + 
  f(y_field, model = spde) + 
  f(yc_field, copy = "z_field", fixed = FALSE)

m_spatial <- inla(f_spatial, 
                  family = c("gamma", "binomial"), 
                  data = inla.stack.data(stack_yz),
                  control.predictor = list(A = inla.stack.A(stack_yz)),
                  control.compute = list(dic = TRUE, config = TRUE))

f_spatials <- alldata ~ -1 + z_intercept + y_intercept + 
  f(site, model = "iid") + 
  f(z_field, model = spde) + 
  f(y_field, model = spde) + 
  f(yc_field, copy = "z_field", fixed = FALSE)

m_spatials <- inla(f_spatials, 
                   family = c("gamma", "binomial"), 
                   data = inla.stack.data(stack_yz),
                   control.predictor = list(A = inla.stack.A(stack_yz)),
                   control.compute = list(dic = TRUE, config = TRUE))

# 5. Spatial-temporal model
f_sptemp <- alldata ~ -1 + z_intercept + y_intercept + 
  f(date, model = "rw2") +
  f(z_field, model = spde) +
  f(y_field, model = spde) + 
  f(yc_field, copy = "z_field", fixed = FALSE)

m_sptemp <- inla(f_sptemp, family = c("gamma", "binomial"),
                 data = inla.stack.data(stack_yz),
                 control.predictor = list(A = inla.stack.A(stack_yz)),
                 control.compute = list(dic = TRUE, config = TRUE))

f_sptemps <- alldata ~ -1 + z_intercept + y_intercept + 
  f(date, model = "rw2") +
  f(site, model = "iid") +
  f(z_field, model = spde) +
  f(y_field, model = spde) + 
  f(yc_field, copy = "z_field", fixed = FALSE)

m_sptemps <- inla(f_sptemps, family = c("gamma", "binomial"),
                  data = inla.stack.data(stack_yz),
                  control.predictor = list(A = inla.stack.A(stack_yz)),
                  control.compute = list(dic = TRUE, config = TRUE))

mods <- list(null = m_null, nulls = m_nulls, 
             time = m_time, times = m_times,
             spatial = m_spatial, spatials = m_spatials, 
             sptemp = m_sptemp, sptemps = m_sptemps)

save(mods, file = "results/model_out.Rda")
```

## Model Comparison

### DIC Comparison

```{r dic}
load("results/model_out.Rda")

# DIC table
map_dfr(mods, function(x) {
  tibble(dic = x$dic$local.dic, family = x$dic$family) %>% 
    group_by(family) %>% 
    summarise(dic = sum(dic)) %>% 
    filter(family %in% c(1, 2)) %>% 
    mutate(measure = c("Abundance", "Occurrence"))
}, .id = "model") %>% 
  select(-family) %>% 
  spread(measure, dic) %>% 
  arrange(Abundance) %>% 
  write_csv("results/dic_table.csv") %>% 
  kable
```

### Predicted vs Observed

```{r, pred_obs}
dat <- dat %>% st_set_geometry(NULL)
idy <- which(dat[,"y"] > 0)
idz <- which(!is.na(dat$z))

pred_vals <- map_dfr(mods[c("nulls", "sptemps")], function(x) {
  df <- tibble(predicted = x$summary.fitted.values$mean, 
             pred_sd = x$summary.fitted.values$sd)
  df[idy, "measure"] <- "Density"
  df[idy, "observed"] <- (dat$y) %>% na.omit
  df[idz + nrow(dat), "measure"] <- "Occurrence"
  df[idz + nrow(dat), "observed"] <- dat$z %>% na.omit
  return(df)
}, .id = "model") %>% na.omit %>% 
  mutate(model = factor(model,
                        levels = c("nulls", "sptemps"),
                        labels = c("null", "spatial")))

corrs <- pred_vals %>% 
  filter(measure == "Density") %>% 
  select(model, observed, predicted) %>% 
  group_by(model) %>% 
  nest() %>% 
  mutate(corr = map_dbl(data, function(x) cor.test(x$observed, x$predicted)$estimate)) %>% 
  select(model, corr) %>% 
  unnest()

density <- ggplot(pred_vals %>% filter(measure == "Density"), 
                  aes(x = observed, y = predicted)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = predicted - pred_sd, ymax = predicted + pred_sd), width = 0) + 
  annotate("text", x = 0.3, y = 0.4, label = paste0("r = ", round(corrs$corr, 3))) +
  facet_wrap(~ model, nrow = 1) + 
  geom_smooth(method = "lm")

occurrence <- ggplot(pred_vals %>% filter(measure == "Occurrence"), 
                     aes(x = as.factor(observed), y = predicted)) + 
  geom_boxplot() + 
  facet_wrap(~ model, nrow = 1) + 
  labs(x = "observed")

density + occurrence + plot_layout(nrow = 2)
```

### Model summary

```{r summ_mod}
summary(mods$sptemps)
```

## Prediction of the response

All predictions use the spatio-temporal model with random effect of site.

NB Results in the paper use 100000 samples from the posterior. We have reduced this to 10 here in the interests of computational time. 

```{r pred_vals}
# get the id's for each field
samples <- inla.posterior.sample(n = 10, result = mods$sptemps)

ids <- lapply(c("y_intercept", "y_field", "yc_field",
                "z_intercept", "z_field"),
              function(x) grep(x, rownames(samples[[1]]$latent), fixed = TRUE))

predict_y <- function(s) exp(s$latent[ids[[1]], 1] + 
                               s$latent[ids[[2]], 1] + 
                               s$latent[ids[[3]], 1])

predict_z <- function(s) 1/ (1 + exp(-(s$latent[ids[[4]], 1] + 
                                        s$latent[ids[[5]], 1])))

pred_y <- sapply(samples, predict_y)
pred_z <- sapply(samples, predict_z)

projgrid <- inla.mesh.projector(mesh, loc = pred_dat)

pred_vals <- as.tibble(pred_dat) %>% 
  mutate(ymean = inla.mesh.project(projgrid, field = rowMeans(pred_y)),
         ylci = inla.mesh.project(projgrid, field = apply(pred_y, 1, quantile, 0.025)),
         yuci = inla.mesh.project(projgrid, field = apply(pred_y, 1, quantile, 0.975)),
         zmean = inla.mesh.project(projgrid, field = rowMeans(pred_z)),
         zlci = inla.mesh.project(projgrid, field = apply(pred_z, 1, quantile, 0.025)),
         zuci = inla.mesh.project(projgrid, field = apply(pred_z, 1, quantile, 0.975)))
```

### Density predictions

```{r density_plot, fig.width = 15, fig.height = 8}
ymean_plot <- ggplot() + 
  geom_sf(data = map_sf, colour = "lightgrey", fill = "lightgrey") + 
  geom_raster(data = pred_vals, aes(x = x, y = y, fill = ymean)) + 
  scale_fill_viridis_c(name = "Density\n(mean)") + 
  labs(x = "", y = "") 

yci_plot <- ggplot() + 
  geom_sf(data = map_sf, colour = "lightgrey", fill = "lightgrey") +
  geom_raster(data = pred_vals, aes(x = x, y = y, fill = yuci - ylci)) + 
  scale_fill_viridis_c(name = "Density\n(95% CI)") + 
  labs(x = "", y = "")

res_plot <- ymean_plot + yci_plot + plot_annotation(tag_levels = "a", tag_suffix = ")")

ggsave(plot = res_plot, filename = "~/Google Drive/SIDEPROJ/Papers/sea cucumber/results.jpg", dpi = 300, width = 140, height = 60, units = "mm")

res_plot
```

### Occurrence predictions

```{r occ_plot, fig.width = 15, fig.height = 8}
zmean_plot <- ggplot() + 
  geom_sf(data = map_sf, colour = "lightgrey", fill = "lightgrey") + 
  geom_raster(data = pred_vals, aes(x = x, y = y, fill = zmean)) + 
  scale_fill_viridis_c(name = "Occurrence (mean)") + 
  labs(x = "", y = "") 

zci_plot <- ggplot() + 
  geom_sf(data = map_sf, colour = "lightgrey", fill = "lightgrey") +
  geom_raster(data = pred_vals, aes(x = x, y = y, fill = zuci - zlci)) + 
  scale_fill_viridis_c(name = "Occurrence (95% CI)") + 
  labs(x = "", y = "")

zmean_plot + zci_plot + plot_annotation(tag_levels = "a", tag_suffix = ")")
```
## Comparison against quotas

We use the shapes from Luis to make predictions of units within the estates for comparison against granted quotas. 

```{r prediction_rasters}
density_mean <- pred_vals %>% 
  select(x, y, ymean) %>% 
  mutate(ymean = ymean * 100 * 100) %>% 
  rasterFromXYZ(crs = crs_ea_mex)

density_lci <- pred_vals %>% 
  select(x, y, ylci) %>% 
  mutate(ylci = ylci * 100 * 100) %>% 
  rasterFromXYZ(crs = crs_ea_mex)

density_uci <- pred_vals %>% 
  select(x, y, yuci) %>% 
  mutate(yuci = yuci * 100 * 100) %>% 
  rasterFromXYZ(crs = crs_ea_mex)

density <- stack(list(mean = density_mean, 
                 lci = density_lci, 
                 uci = density_uci))

# for the null models
ymean <- exp(mods$times$summary.fixed[2, 1]) * 100 * 100
ylci <- exp(mods$times$summary.fixed[2, 3]) * 100 * 100
yuci <- exp(mods$times$summary.fixed[2, 5]) * 100 * 100
nulldensity_mean <- density_mean
nulldensity_lci <- density_lci
nulldensity_uci <- density_uci
values(nulldensity_mean) <- ifelse(is.na(values(nulldensity_mean)), NA, ymean)
values(nulldensity_lci) <- ifelse(is.na(values(nulldensity_lci)), NA, ylci)
values(nulldensity_uci) <- ifelse(is.na(values(nulldensity_uci)), NA, yuci)

nulldensity <- stack(list(nullmean = nulldensity_mean,
                          nulllci = nulldensity_lci,
                          nulluci = nulldensity_uci))
```

```{r quota_preds}
quota_preds <- raster::extract(density, quotas_sp, fun = sum, na.rm = TRUE) %>% as_tibble
quota_nullpreds <- raster::extract(nulldensity, quotas_sp, fun = sum, na.rm = TRUE) %>% as_tibble
quota_area <- raster::extract(density, quotas_sp) %>% 
  map_dfr(function(x) {
    tibble(suitable_area = x %>% na.omit %>% nrow)
  })

bind_cols(quotas, quota_preds, quota_nullpreds, quota_area) %>% 
  st_set_geometry(NULL) %>% 
  mutate(uniform = 0.3*10^4*total_area*0.1,
         smean = mean*0.1,
         slci = lci*0.1,
         nmean = nullmean*0.1,
         nlci = nulllci*0.1) %>% 
  arrange(Estate) %>% 
  select(Estate, total_area, suitable_area, # info on estates
         mean, lci, uci, # spatial model estimates
         nullmean, nulllci, nulluci, # non-spatial model estimates
         uniform, smean, slci, nmean, nlci) %>% # quotas
  write_csv("results/quotas.csv") %>% 
  kable
```

Plot showing the estimated quotas (mean and LCI) against the granted quotas. 

```{r}
dat <- bind_cols(read_csv("results/quotas.csv"), 
                 tibble(granted_quota = c(6750, 6750, 6250, 6750, 6250, 47088, 27390, 24315, 12158))) %>% 
  mutate(Estate = factor(Estate)) %>% 
  mutate(legend = " Granted Quota")

                 
table1 <- dat %>% 
  select(Estate, total_area, suitable_area, mean, lci, uci, nullmean, nulllci, nulluci) %>% 
  write_csv("results/table1.csv")

fig3_dat <- dat %>% 
  select(Estate, spatial_mean = mean, spatial_lci = lci, nonspatial_mean = nullmean, nonspatial_lci = nulllci) %>% 
  mutate_at(vars(spatial_mean, spatial_lci, nonspatial_mean, nonspatial_lci), .funs = function(x) x*0.1) %>% 
  gather(key, value, -Estate) %>%
  separate(key, into = c("model", "measure")) %>% 
  spread(measure, value) %>% 
  mutate(Model = factor(model, levels = c("spatial", "nonspatial"), labels = c(" Spatial model (-95% CI)", " Non-spatial model (-95% CI)")))

ggplot() + 
  geom_bar(data = dat, aes(x = Estate, y = granted_quota, fill = legend), stat = "identity", colour = "black") + 
  scale_fill_manual(values = "white") + 
  geom_point(data = fig3_dat, aes(x = Estate, y = mean, shape = Model), position = position_dodge(1), size = 3) + 
  geom_point(data = fig3_dat, aes(x = Estate, y = lci, group = Model), shape = 95, size = 2, position = position_dodge(1)) + 
  geom_linerange(data = fig3_dat, aes(x = Estate, ymin = lci, ymax = mean, group = Model), position = position_dodge(1)) + 
  ylab("Quota (in number of pieces of sea cucumber)") + 
  theme(legend.position = c(0.15, 0.8),
        legend.title = element_blank())

ggsave(filename = "~/Google Drive/SIDEPROJ/Papers/sea cucumber/3_quotas.jpg", dpi = 300, width = 140, height = 80, units = "mm")
  
```

